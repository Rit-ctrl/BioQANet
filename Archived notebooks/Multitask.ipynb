{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from transformers import AutoModel,AutoTokenizer\n",
    "from utils import *\n",
    "from config import data_path,save_path\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fada9b85f90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) |available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) |available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def virtual_adversarial_training(model, input_ids, attention_mask, epsilon=1.0, alpha=1.0, n_iterations=1):\n",
    "    # Initial forward pass\n",
    "    with torch.no_grad():\n",
    "        initial_logits, _ = model(input_ids, attention_mask)\n",
    "        initial_prob = F.softmax(initial_logits, dim=1)\n",
    "\n",
    "    # Initialize perturbation\n",
    "    d = torch.randn_like(input_ids, dtype=torch.float).to(input_ids.device)\n",
    "    d = F.normalize(d, dim=-1, p=2)\n",
    "    d.requires_grad_()\n",
    "\n",
    "    # print(epsilon)\n",
    "    # print(d)\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Forward pass with perturbed input\n",
    "        perturbed_ids = input_ids.float() + epsilon * d\n",
    "        logits_perturbed, _ = model(perturbed_ids.long(), attention_mask)\n",
    "        \n",
    "        # Compute KL divergence\n",
    "        loss = F.kl_div(F.log_softmax(logits_perturbed, dim=1),\n",
    "                        initial_prob,\n",
    "                        reduction='batchmean')\n",
    "        \n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update perturbation\n",
    "        if d.grad is not None:\n",
    "            d = d.grad.detach()\n",
    "            d = F.normalize(d, dim=-1, p=2)\n",
    "            d.requires_grad_()\n",
    "        else:\n",
    "            # If gradient is None, reinitialize d\n",
    "            d = torch.randn_like(input_ids, dtype=torch.float).to(input_ids.device)\n",
    "            d = F.normalize(d, dim=-1, p=2)\n",
    "            d.requires_grad_()\n",
    "        \n",
    "        model.zero_grad()\n",
    "\n",
    "    # Final forward pass with adversarial perturbation\n",
    "    with torch.no_grad():\n",
    "        adv_ids = (input_ids.float() + epsilon * d).long()\n",
    "        logits_adv, _ = model(adv_ids, attention_mask)\n",
    "    \n",
    "    # Compute VAT loss\n",
    "    vat_loss = F.kl_div(F.log_softmax(logits_adv, dim=1),\n",
    "                        initial_prob,\n",
    "                        reduction='batchmean')\n",
    "    \n",
    "    return alpha * vat_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskPubMedQA(nn.Module):\n",
    "    def __init__(self, model_name='dmis-lab/biobert-base-cased-v1.1', num_labels=3):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.long_answer_generator = nn.Linear(self.bert.config.hidden_size, self.bert.config.vocab_size)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        \n",
    "        # Task 1: Yes/No/Maybe Classification\n",
    "        classification_logits = self.classifier(pooled_output)\n",
    "        \n",
    "        # Task 2: Long Answer Generation\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        long_answer_logits = self.long_answer_generator(sequence_output)\n",
    "        \n",
    "        return classification_logits, long_answer_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at nlpie/tiny-biobert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'nlpie/tiny-biobert'\n",
    "model = MultiTaskPubMedQA(model_name = model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_train_processed,artificial_train_processed,unlabeled_processed,expert_test_processed = load_pubmedqa_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PubMedQADataset(expert_train_processed + artificial_train_processed, tokenizer,max_length = 256)\n",
    "# val_dataset = PubMedQADataset(expert_val, tokenizer)\n",
    "unlabeled_dataset = PubMedQADataset(unlabeled_processed, tokenizer,max_length = 256)\n",
    "test_dataset = PubMedQADataset(expert_test_processed,tokenizer,max_length = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count_list = [196420, 15294, 55]\n",
    "class_weights = [max(class_count_list) / count for count in class_count_list]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "classification_loss_fn = nn.CrossEntropyLoss(weight = class_weights)\n",
    "generation_loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2372, 16979,  ...,  1833,  2366,   102],\n",
       "         [  101, 12120, 20954,  ...,  1121,  1103,   102],\n",
       "         [  101,  8274,   118,  ...,  8167, 10721,   102],\n",
       "         ...,\n",
       "         [  101,  7187,  1425,  ...,  1127,  2382,   102],\n",
       "         [  101,  2181, 11019,  ...,   119,   121,   102],\n",
       "         [  101,   140,  3161,  ...,   110,   117,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1]]),\n",
       " 'label': tensor([-1, -1, -1, -1, -1, -1, -1, -1]),\n",
       " 'long_answer_ids': tensor([[101, 102,   0,  ...,   0,   0,   0],\n",
       "         [101, 102,   0,  ...,   0,   0,   0],\n",
       "         [101, 102,   0,  ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [101, 102,   0,  ...,   0,   0,   0],\n",
       "         [101, 102,   0,  ...,   0,   0,   0],\n",
       "         [101, 102,   0,  ...,   0,   0,   0]]),\n",
       " 'long_answer_mask': tensor([[1, 1, 0,  ..., 0, 0, 0],\n",
       "         [1, 1, 0,  ..., 0, 0, 0],\n",
       "         [1, 1, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 0,  ..., 0, 0, 0],\n",
       "         [1, 1, 0,  ..., 0, 0, 0],\n",
       "         [1, 1, 0,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(unlabeled_loader))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# import gc\n",
    "# del variables\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy before phase 1 : 0.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy before phase 1 : {get_acc(model,test_loader,device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   500  of  7,657 time elapsed 0:02:00\n",
      "  Batch 1,000  of  7,657 time elapsed 0:04:01\n",
      "  Batch 1,500  of  7,657 time elapsed 0:06:02\n",
      "  Batch 2,000  of  7,657 time elapsed 0:08:04\n",
      "  Batch 2,500  of  7,657 time elapsed 0:10:05\n",
      "  Batch 3,000  of  7,657 time elapsed 0:12:06\n",
      "  Batch 3,500  of  7,657 time elapsed 0:14:07\n",
      "  Batch 4,000  of  7,657 time elapsed 0:16:08\n",
      "  Batch 4,500  of  7,657 time elapsed 0:18:09\n",
      "  Batch 5,000  of  7,657 time elapsed 0:20:10\n",
      "  Batch 5,500  of  7,657 time elapsed 0:22:11\n",
      "  Batch 6,000  of  7,657 time elapsed 0:24:12\n",
      "  Batch 6,500  of  7,657 time elapsed 0:26:13\n",
      "  Batch 7,000  of  7,657 time elapsed 0:28:15\n",
      "  Batch 7,500  of  7,657 time elapsed 0:30:16\n",
      "Epoch 0 loss : 166.08718601762666\n",
      "  Batch   500  of  7,657 time elapsed 0:32:55\n",
      "  Batch 1,000  of  7,657 time elapsed 0:34:56\n",
      "  Batch 1,500  of  7,657 time elapsed 0:36:57\n",
      "  Batch 2,000  of  7,657 time elapsed 0:38:58\n",
      "  Batch 2,500  of  7,657 time elapsed 0:40:59\n",
      "  Batch 3,000  of  7,657 time elapsed 0:43:00\n",
      "  Batch 3,500  of  7,657 time elapsed 0:45:01\n",
      "  Batch 4,000  of  7,657 time elapsed 0:47:03\n",
      "  Batch 4,500  of  7,657 time elapsed 0:49:04\n",
      "  Batch 5,000  of  7,657 time elapsed 0:51:05\n",
      "  Batch 5,500  of  7,657 time elapsed 0:53:06\n",
      "  Batch 6,000  of  7,657 time elapsed 0:55:07\n",
      "  Batch 6,500  of  7,657 time elapsed 0:57:08\n",
      "  Batch 7,000  of  7,657 time elapsed 0:59:09\n",
      "  Batch 7,500  of  7,657 time elapsed 1:01:10\n",
      "Epoch 1 loss : 4.3893997131235665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy after phase 1 : 0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "\n",
    "    for step,batch in enumerate(unlabeled_loader):\n",
    "\n",
    "        # input_ids, attention_mask, label, long_answer, = batch\n",
    "        # batch = batch.to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        long_answer_ids = batch['long_answer_ids'].to(device)\n",
    "\n",
    "        \n",
    "        classification_logits, long_answer_logits = model(input_ids, attention_mask)\n",
    "        \n",
    "        # Compute losses\n",
    "        # classification_loss = classification_loss_fn(classification_logits, label)\n",
    "        # In your training loop\n",
    "        vat_loss = virtual_adversarial_training(model, input_ids, attention_mask,n_iterations=5)\n",
    "\n",
    "        generation_loss = generation_loss_fn(long_answer_logits.view(-1, long_answer_logits.size(-1)), long_answer_ids.view(-1))\n",
    "\n",
    "        # Combine losses\n",
    "        total_loss = vat_loss + generation_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            \n",
    "            # Report progress.\n",
    "            total_time = time.time() - total_start_time\n",
    "            print('  Batch {:>5,}  of  {:>5,} time elapsed {}'.format(step, len(unlabeled_loader),format_time(total_time)))\n",
    "        # generation_loss.backward()\n",
    "        epoch_loss += total_loss.item()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch} loss : {epoch_loss}\")\n",
    "\n",
    "    \n",
    "print(f\"Test Accuracy after phase 1 : {get_acc(model,test_loader,device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1844, 0.552"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"weights/phase_1_model_{num_epochs}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'epochs': num_epochs,\n",
    "    'lr':3e-4\n",
    "}\n",
    "torch.save(state, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy after phase 1 : 0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy after phase 1 : {get_acc(model,test_loader,device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [12:27,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 3,000  of  26,472 time elapsed 0:12:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [24:56,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 6,000  of  26,472 time elapsed 0:24:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9001it [37:25,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 9,000  of  26,472 time elapsed 0:37:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12001it [49:53,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 12,000  of  26,472 time elapsed 0:49:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15001it [1:02:22,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 15,000  of  26,472 time elapsed 1:02:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18001it [1:14:50,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 18,000  of  26,472 time elapsed 1:14:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21001it [1:27:19,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 21,000  of  26,472 time elapsed 1:27:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24001it [1:39:48,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 24,000  of  26,472 time elapsed 1:39:48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26472it [1:50:05,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss : 197524.51847219467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.train()\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for step,batch in tqdm(enumerate(train_loader)):\n",
    "\n",
    "        # batch = batch.to(device)\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        long_answer_ids = batch['long_answer_ids'].to(device)\n",
    "        # long_answer_mask = batch['long_answer_mask']\n",
    "\n",
    "        # 'input_ids' : inputs['input_ids'].squeeze(),\n",
    "        #     'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "        #     'label':label,\n",
    "        #     'long_answer_ids': long_answer_encoding['input_ids'].squeeze(),\n",
    "        #     'long_answer_mask': long_answer_encoding['attention_mask'].squeeze()\n",
    "        # input_ids, attention_mask = prepare_data(question, context)\n",
    "        \n",
    "        classification_logits, long_answer_logits = model(input_ids, attention_mask)\n",
    "        \n",
    "        # Compute losses\n",
    "        classification_loss = classification_loss_fn(classification_logits, label)\n",
    "        vat_loss = virtual_adversarial_training(model, input_ids, attention_mask,n_iterations=5)\n",
    "\n",
    "        generation_loss = generation_loss_fn(long_answer_logits.view(-1, long_answer_logits.size(-1)), long_answer_ids.view(-1))\n",
    "\n",
    "        # Combine losses\n",
    "        total_loss = classification_loss + generation_loss + vat_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "\n",
    "        if step % 3000 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            \n",
    "            # Report progress.\n",
    "            total_time = time.time() - total_start_time\n",
    "            print('  Batch {:>5,}  of  {:>5,} time elapsed {}'.format(step, len(train_loader),format_time(total_time)))\n",
    "        optimizer.step()\n",
    "        epoch_loss += total_loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch} loss : {epoch_loss}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy after phase 2 : 0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy after phase 2 : {get_acc(model,test_loader,device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'epochs': 2,\n",
    "    'lr':3e-4\n",
    "}\n",
    "torch.save(state, \"weights/phase_2_model_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "199071.09152078629, 0.552\n",
    "197524.51847219467, 0.496\n",
    "\n",
    "# 171688.996986866, 0.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f\"weights/phase_1_model_{num_epochs}.pt\")\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f\"weights/phase_2_model_{num_epochs}.pt\")\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

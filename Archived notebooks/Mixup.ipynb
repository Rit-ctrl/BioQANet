{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import random\n",
    "from torch import nn\n",
    "from transformers import AutoModel,AutoTokenizer\n",
    "from utils import *\n",
    "from config import data_path,save_path\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "# torch.manual_seed_all(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) |available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) |available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixMatch:\n",
    "    def __init__(self, model, tokenizer, num_classes, T=0.5, K=2, alpha=0.75, lambda_u=75):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.num_classes = num_classes\n",
    "        self.T = T\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.lambda_u = lambda_u\n",
    "\n",
    "    def temperature_sharpening(self, probs):\n",
    "        probs = probs.pow(1/self.T)\n",
    "        return probs / probs.sum(dim=1, keepdim=True)\n",
    "\n",
    "    def mixup(self, x1, x2, y1, y2):\n",
    "        lambda_ = np.random.beta(self.alpha, self.alpha)\n",
    "        lambda_ = max(lambda_, 1 - lambda_)\n",
    "        \n",
    "        # Perform mixup on embeddings instead of input_ids\n",
    "        with torch.no_grad():\n",
    "            embed1 = self.model.bert.embeddings.word_embeddings(x1)\n",
    "            embed2 = self.model.bert.embeddings.word_embeddings(x2)\n",
    "        \n",
    "        mixed_embed = lambda_ * embed1 + (1 - lambda_) * embed2\n",
    "        mixed_y = lambda_ * y1 + (1 - lambda_) * y2\n",
    "        \n",
    "        return mixed_embed, mixed_y\n",
    "\n",
    "    def augment(self, input_ids, attention_mask, p=0.1):\n",
    "        # Random deletion augmentation\n",
    "        batch_size, seq_length = input_ids.size()\n",
    "        augmented_input_ids = input_ids.clone()\n",
    "        augmented_attention_mask = attention_mask.clone()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # Find the actual sequence length for this example\n",
    "            actual_length = attention_mask[i].sum().item()\n",
    "            \n",
    "            # Only augment if the sequence is long enough\n",
    "            if actual_length > 2:  # We need at least 3 tokens to perform deletion\n",
    "                tokens = input_ids[i][:actual_length]\n",
    "                n_to_delete = max(1, int(p * (actual_length - 2)))  # Ensure we keep at least 2 tokens\n",
    "                \n",
    "                # Randomly choose tokens to delete, excluding the first and last tokens\n",
    "                indices_to_keep = [0] + random.sample(range(1, actual_length - 1), actual_length - 2 - n_to_delete) + [actual_length - 1]\n",
    "                indices_to_keep.sort()\n",
    "                \n",
    "                # Create the new sequence\n",
    "                new_tokens = tokens[indices_to_keep]\n",
    "                \n",
    "                # Pad the sequence to maintain original length\n",
    "                padding_length = seq_length - len(new_tokens)\n",
    "                new_tokens = torch.cat([new_tokens, torch.full((padding_length,), self.tokenizer.pad_token_id, device=new_tokens.device)])\n",
    "                \n",
    "                # Update input_ids and attention_mask\n",
    "                augmented_input_ids[i] = new_tokens\n",
    "                augmented_attention_mask[i] = torch.cat([torch.ones(len(indices_to_keep), device=attention_mask.device), \n",
    "                                                         torch.zeros(padding_length, device=attention_mask.device)])\n",
    "        \n",
    "        return augmented_input_ids, augmented_attention_mask\n",
    "\n",
    "    def process_batch(self, labeled_batch, unlabeled_batch):\n",
    "        x_labeled, y_labeled = labeled_batch['input_ids'], labeled_batch['label']\n",
    "        x_unlabeled, attention_mask_unlabeled = unlabeled_batch['input_ids'], unlabeled_batch['attention_mask']\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            # Generate pseudo-labels for unlabeled data\n",
    "            qb_unlabeled = torch.zeros(x_unlabeled.size(0), self.num_classes).to(x_labeled.device)\n",
    "            for _ in range(self.K):\n",
    "                x_augmented, attention_mask_augmented = self.augment(x_unlabeled, attention_mask_unlabeled)\n",
    "                logits = self.model(x_augmented, attention_mask_augmented)\n",
    "                qb_unlabeled += F.softmax(logits, dim=1)\n",
    "            qb_unlabeled /= self.K\n",
    "    \n",
    "            # Apply temperature sharpening\n",
    "            qb_unlabeled = self.temperature_sharpening(qb_unlabeled)\n",
    "    \n",
    "        # Concatenate labeled and unlabeled data\n",
    "        x_all = torch.cat([x_labeled, x_unlabeled], dim=0)\n",
    "        y_all = torch.cat([F.one_hot(y_labeled, num_classes=self.num_classes).float(), qb_unlabeled], dim=0)\n",
    "        attention_mask_all = torch.cat([labeled_batch['attention_mask'], attention_mask_unlabeled], dim=0)\n",
    "    \n",
    "        # Shuffle for MixUp\n",
    "        indices = torch.randperm(x_all.size(0))\n",
    "        x_shuffled = x_all[indices]\n",
    "        y_shuffled = y_all[indices]\n",
    "        attention_mask_shuffled = attention_mask_all[indices]\n",
    "    \n",
    "        # Apply MixUp on embeddings\n",
    "        mixed_embed, y_mixed = self.mixup(x_all, x_shuffled, y_all, y_shuffled)\n",
    "        attention_mask_mixed = attention_mask_all  # Attention mask doesn't change in MixUp\n",
    "    \n",
    "        # Split mixed data back into labeled and unlabeled\n",
    "        batch_size = x_labeled.size(0)\n",
    "        embed_labeled_mixed = mixed_embed[:batch_size]\n",
    "        y_labeled_mixed = y_mixed[:batch_size]\n",
    "        embed_unlabeled_mixed = mixed_embed[batch_size:]\n",
    "        y_unlabeled_mixed = y_mixed[batch_size:]\n",
    "        attention_mask_labeled_mixed = attention_mask_mixed[:batch_size]\n",
    "        attention_mask_unlabeled_mixed = attention_mask_mixed[batch_size:]\n",
    "    \n",
    "        return embed_labeled_mixed, y_labeled_mixed, embed_unlabeled_mixed, y_unlabeled_mixed, attention_mask_labeled_mixed, attention_mask_unlabeled_mixed\n",
    "    \n",
    "    def compute_loss(self, embed_labeled, y_labeled, embed_unlabeled, y_unlabeled, attention_mask_labeled, attention_mask_unlabeled):\n",
    "        # Compute loss for labeled data\n",
    "        logits_labeled = self.model.bert(inputs_embeds=embed_labeled, attention_mask=attention_mask_labeled).last_hidden_state[:, 0, :]\n",
    "        logits_labeled = self.model.classifier(logits_labeled)\n",
    "        class_weights = torch.tensor([1.0000e+00, 1.2843e+01, 3.5713e+03], dtype=torch.float).to('cuda')\n",
    "        loss_labeled = F.cross_entropy(logits_labeled, y_labeled.argmax(dim=1),weight = class_weights )\n",
    "    \n",
    "        # Compute loss for unlabeled data\n",
    "        logits_unlabeled = self.model.bert(inputs_embeds=embed_unlabeled, attention_mask=attention_mask_unlabeled).last_hidden_state[:, 0, :]\n",
    "        logits_unlabeled = self.model.classifier(logits_unlabeled)\n",
    "        loss_unlabeled = F.mse_loss(F.softmax(logits_unlabeled, dim=1), y_unlabeled)\n",
    "    \n",
    "        # Combine losses\n",
    "        total_loss = loss_labeled + self.lambda_u * loss_unlabeled\n",
    "    \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixMatchDataLoader:\n",
    "    def __init__(self, labeled_loader, unlabeled_loader):\n",
    "        self.labeled_loader = labeled_loader\n",
    "        self.unlabeled_loader = unlabeled_loader\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.labeled_iter = iter(self.labeled_loader)\n",
    "        self.unlabeled_iter = iter(self.unlabeled_loader)\n",
    "        self.num_batches = max(len(self.labeled_loader), len(self.unlabeled_loader))\n",
    "        self.current_batch = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.reset()\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_batch >= self.num_batches:\n",
    "            raise StopIteration\n",
    "\n",
    "        try:\n",
    "            labeled_batch = next(self.labeled_iter)\n",
    "        except StopIteration:\n",
    "            self.labeled_iter = iter(self.labeled_loader)\n",
    "            labeled_batch = next(self.labeled_iter)\n",
    "\n",
    "        try:\n",
    "            unlabeled_batch = next(self.unlabeled_iter)\n",
    "        except StopIteration:\n",
    "            self.unlabeled_iter = iter(self.unlabeled_loader)\n",
    "            unlabeled_batch = next(self.unlabeled_iter)\n",
    "\n",
    "        self.current_batch += 1\n",
    "        return labeled_batch, unlabeled_batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, mixmatch, train_loader,test_loader,optimizer, device, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for labeled_batch, unlabeled_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            labeled_batch = {k: v.to(device) for k, v in labeled_batch.items()}\n",
    "            unlabeled_batch = {k: v.to(device) for k, v in unlabeled_batch.items()}\n",
    "            \n",
    "            embed_labeled_mixed, y_labeled_mixed, embed_unlabeled_mixed, y_unlabeled_mixed, attention_mask_labeled_mixed, attention_mask_unlabeled_mixed = mixmatch.process_batch(labeled_batch, unlabeled_batch)\n",
    "            \n",
    "            loss = mixmatch.compute_loss(\n",
    "                embed_labeled_mixed, y_labeled_mixed, embed_unlabeled_mixed, y_unlabeled_mixed,\n",
    "                attention_mask_labeled_mixed, attention_mask_unlabeled_mixed\n",
    "            )\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "        print(f\"Test Accuracy after training : {get_acc(model,test_loader,device)}\")\n",
    "        model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PubMedQAModel(nn.Module):\n",
    "    def __init__(self, pretrained_model_name='microsoft/biobert-base-cased-v1.1'):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(pretrained_model_name)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 3)  # 3 classes: yes, no, maybe\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, inputs_embeds=None):\n",
    "        if input_ids is not None:\n",
    "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        else:\n",
    "            outputs = self.bert(inputs_embeds=inputs_embeds, attention_mask=attention_mask)\n",
    "        logits = self.classifier(outputs.pooler_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nlpie/tiny-biobert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at nlpie/tiny-biobert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = PubMedQAModel(pretrained_model_name = model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_train_processed,artificial_train_processed,unlabeled_processed,expert_test_processed = load_pubmedqa_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PubMedQADataset(expert_train_processed + artificial_train_processed, tokenizer,max_length = 400)\n",
    "# val_dataset = PubMedQADataset(expert_val, tokenizer)\n",
    "unlabeled_dataset = PubMedQADataset(unlabeled_processed, tokenizer,max_length = 400)\n",
    "test_dataset = PubMedQADataset(expert_test_processed,tokenizer,max_length = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixmatch_loader = MixMatchDataLoader(labeled_loader, unlabeled_loader)\n",
    "mixmatch = MixMatch(model, tokenizer, num_classes=3)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26472, 7657)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_loader), len(unlabeled_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26472"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mixmatch_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy before phase 1 : 0.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy before phase 1 : {get_acc(model,test_loader,device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e0b619ac034ffdbc9d962117abb084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/26472 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 1.0637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy after training : 0.336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8f413736974c0f8e98391b5e80a15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/2:   0%|          | 0/26472 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2, Loss: 0.9089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy after training : 0.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, mixmatch, mixmatch_loader, test_loader,optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# import gc\n",
    "# del variables\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy after phase 1 : 0.332\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy after phase 1 : {get_acc(model,test_loader,device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1844, 0.552"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"mixup_{num_epochs}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'epochs': num_epochs,\n",
    "    'lr':2e-5\n",
    "}\n",
    "torch.save(state, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'MixMatchDataLoader' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmixmatch_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'MixMatchDataLoader' has no len()"
     ]
    }
   ],
   "source": [
    "len(mixmatch_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test Accuracy after phase 2 : {get_acc(model,test_loader,device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "}\n",
    "torch.save(state, \"phase_2_model_2_epochs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "175503, 0.576\n",
    "171688.996986866, 0.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"phase_2_model.pt\")\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
